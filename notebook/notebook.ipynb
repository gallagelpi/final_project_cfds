{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from best_library import LoadData, Preprocessing, FeatureBuilder, DatasetSplitter, ModelResnet18, HyperparameterTuner, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DATASET_DIR = \"../dataset\"   # raw dataset\n",
    "WORK_DIR = \"../data\"         # working directory for split dataset\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-4\n",
    "EPOCHS = 5\n",
    "IMG_SIZE = 224\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SAVE_PATH = \"../models/best_model.pth\"\n",
    "\n",
    "if os.path.exists(WORK_DIR):\n",
    "    shutil.rmtree(WORK_DIR)\n",
    "\n",
    "os.makedirs(f\"{WORK_DIR}/train/alpaca\", exist_ok=True)\n",
    "os.makedirs(f\"{WORK_DIR}/train/not_alpaca\", exist_ok=True)\n",
    "os.makedirs(f\"{WORK_DIR}/val/alpaca\", exist_ok=True)\n",
    "os.makedirs(f\"{WORK_DIR}/val/not_alpaca\", exist_ok=True)\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# a) Preprocessing\n",
    "# ====================================================\n",
    "\n",
    "# Creating the transform that we are going to apply later to the images\n",
    "\n",
    "preprocessor = Preprocessing(img_size=IMG_SIZE)\n",
    "transform = preprocessor.get_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset...\n",
      "Dataset split complete!\n",
      "Training folders: ['alpaca', 'not_alpaca']\n",
      "Validation folders: ['alpaca', 'not_alpaca']\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# b) Split dataset\n",
    "# ====================================================\n",
    "\n",
    "# Filling the dataset with 2 folders train and val, each containing alpaca and not_alpaca folders\n",
    "\n",
    "splitter = DatasetSplitter(DATASET_DIR, WORK_DIR, train_ratio=0.8)\n",
    "splitter.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes detected: ['alpaca', 'not_alpaca']\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# c) Load datasets with DataLoaders\n",
    "# ====================================================\n",
    "\n",
    "# Applying transformations to the dataset and creating two iterables for all the pictures in the training and validation\n",
    "\n",
    "loader = LoadData(WORK_DIR, transform=transform)\n",
    "train_loader, val_loader, class_names = loader.load_and_split(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# d) Feature building\n",
    "# ====================================================\n",
    "feature_builder = FeatureBuilder()\n",
    "# Example usage:\n",
    "for images, labels in train_loader:\n",
    "    feats = feature_builder.extract_features(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Acc: 0.858 | Val Acc: 0.879\n",
      "Epoch 2/5 | Train Acc: 0.992 | Val Acc: 0.909\n",
      "Epoch 3/5 | Train Acc: 1.000 | Val Acc: 0.864\n",
      "Epoch 4/5 | Train Acc: 0.996 | Val Acc: 0.894\n",
      "Epoch 5/5 | Train Acc: 0.981 | Val Acc: 0.909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# e) Build and train the first model\n",
    "# ====================================================\n",
    "model_api = ModelResnet18(device=DEVICE, class_names=class_names)\n",
    "model = model_api.build_model()\n",
    "\n",
    "model_api.train_model(model, train_loader, val_loader, epochs=EPOCHS, lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning with 4 combinations...\n",
      "\n",
      "--- Trial 1/4: {'lr': 0.001, 'epochs': 3} ---\n",
      "Epoch 1/3 | Train Acc: 0.759 | Val Acc: 0.636\n",
      "Epoch 2/3 | Train Acc: 0.843 | Val Acc: 0.515\n",
      "Epoch 3/3 | Train Acc: 0.858 | Val Acc: 0.818\n",
      "Trial finished. Validation accuracy: 0.818\n",
      "\n",
      "--- Trial 2/4: {'lr': 0.001, 'epochs': 5} ---\n",
      "Epoch 1/5 | Train Acc: 0.770 | Val Acc: 0.682\n",
      "Epoch 2/5 | Train Acc: 0.751 | Val Acc: 0.530\n",
      "Epoch 3/5 | Train Acc: 0.916 | Val Acc: 0.758\n",
      "Epoch 4/5 | Train Acc: 0.920 | Val Acc: 0.848\n",
      "Epoch 5/5 | Train Acc: 0.908 | Val Acc: 0.788\n",
      "Trial finished. Validation accuracy: 0.788\n",
      "\n",
      "--- Trial 3/4: {'lr': 0.0001, 'epochs': 3} ---\n",
      "Epoch 1/3 | Train Acc: 0.793 | Val Acc: 0.924\n",
      "Epoch 2/3 | Train Acc: 0.981 | Val Acc: 0.909\n",
      "Epoch 3/3 | Train Acc: 0.992 | Val Acc: 0.924\n",
      "Trial finished. Validation accuracy: 0.924\n",
      "\n",
      "--- Trial 4/4: {'lr': 0.0001, 'epochs': 5} ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m param_grid = {\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m1e-3\u001b[39m, \u001b[32m1e-4\u001b[39m],\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m]\n\u001b[32m      7\u001b[39m }\n\u001b[32m      9\u001b[39m tuner = HyperparameterTuner(param_grid, DEVICE)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m best_params, best_acc = \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSAVE_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Best validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/FINAL PROJECT TEST CFDS/final_project_cfds/src/best_library/hyperparameter_tuning/tuner.py:82\u001b[39m, in \u001b[36mHyperparameterTuner.tune\u001b[39m\u001b[34m(self, train_loader, val_loader, save_path)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(param_combinations)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m model = model_api.build_model(num_classes=num_classes)\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m val_acc = \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_api\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m results.append((params, val_acc))\n\u001b[32m     88\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrial finished. Validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/FINAL PROJECT TEST CFDS/final_project_cfds/src/best_library/hyperparameter_tuning/tuner.py:19\u001b[39m, in \u001b[36mtrain_and_evaluate_model\u001b[39m\u001b[34m(model, train_loader, val_loader, model_api, lr, epochs)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_and_evaluate_model\u001b[39m(model, train_loader, val_loader, model_api: ModelResnet18, lr: \u001b[38;5;28mfloat\u001b[39m, epochs: \u001b[38;5;28mint\u001b[39m):\n\u001b[32m     16\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m    Train model (without saving) and return validation accuracy.\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[43mmodel_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     val_acc = evaluate_model(model, val_loader, model_api.device)\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m val_acc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/FINAL PROJECT TEST CFDS/final_project_cfds/src/best_library/model/model_resnet18.py:74\u001b[39m, in \u001b[36mModelResnet18.train_model\u001b[39m\u001b[34m(self, model, train_loader, val_loader, epochs, lr)\u001b[39m\n\u001b[32m     72\u001b[39m outputs = model(images)\n\u001b[32m     73\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m optimizer.step()\n\u001b[32m     77\u001b[39m preds = torch.argmax(outputs, dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/FINAL PROJECT TEST CFDS/final_project_cfds/.venv/lib/python3.11/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/FINAL PROJECT TEST CFDS/final_project_cfds/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/FINAL PROJECT TEST CFDS/final_project_cfds/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# f) Hyperparameter tuning\n",
    "# ====================================================\n",
    "param_grid = {\n",
    "    \"lr\": [1e-3, 1e-4],\n",
    "    \"epochs\": [3, 5]\n",
    "}\n",
    "\n",
    "tuner = HyperparameterTuner(param_grid, DEVICE)\n",
    "best_params, best_acc = tuner.tune(train_loader, val_loader, save_path=SAVE_PATH)\n",
    "print(f\"Best hyperparameters: {best_params}, Best validation accuracy: {best_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy of the best model: 0.864\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# g) Evaluate model\n",
    "# ====================================================\n",
    "evaluator = Evaluator(DEVICE)\n",
    "best_model = model_api.load_trained_model(SAVE_PATH)\n",
    "val_accuracy = evaluator.evaluate(best_model, val_loader)\n",
    "print(f\"Validation accuracy of the best model: {val_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: not_alpaca, Confidence: 0.966\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# h) Predict new images \n",
    "# ====================================================\n",
    "image_path = \"../dog2.jpg\"\n",
    "label, confidence = model_api.predict(image_path, best_model, transform)\n",
    "print(f\"Predicted label: {label}, Confidence: {confidence:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
